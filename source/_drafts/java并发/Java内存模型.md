---
title: Java内存模型
date: 2020-04-19 20:03:27
tags: 并发
categories: java
thumbnail:
---

## 高速缓存

<!--more-->

在讲解Java内存模型(JMM)之前，我觉得阐述一下高速缓存很有必要.高速缓存的定义如下：

> 在[计算机](https://zh.wikipedia.org/wiki/计算机)系统中，**CPU高速缓存**（英语：CPU Cache，在本文中简称缓存）是用于减少[处理器](https://zh.wikipedia.org/wiki/中央处理器)访问内存所需平均时间的部件。在金字塔式[存储体系](https://zh.wikipedia.org/w/index.php?title=存储体系&action=edit&redlink=1)中它位于自顶向下的第二层，仅次于[CPU寄存器](https://zh.wikipedia.org/wiki/寄存器)。其容量远小于[内存](https://zh.wikipedia.org/wiki/内存)，但速度却可以接近处理器的频率。
>
> 当处理器发出内存访问请求时，会先查看缓存内是否有请求数据。如果存在（命中），则不经访问内存直接返回该数据；如果不存在（失效），则要先把内存中的相应数据载入缓存，再将其返回处理器。---- [维基百科](https://zh.wikipedia.org/wiki/CPU缓存)

![金字塔式存储体系.jpg](https://i.loli.net/2020/04/24/dKWnsATCNwoD7fq.jpg)

为什么要用`高速缓存`，说白了，就是因为CPU的性能比Memory快得多，所以使用高速缓存来拟补之间的差距，CPU在执行时会先从缓存中获取任务，若是，缓存中没有，才回进入内存中调取任务。

### 缓存一致性

解决了处理机和内存的交互效率问题， 还有一个问题就是缓存用的一致性，在多处理机中，每个处理机都有自己的`高速缓存`，并且多个处理机共享同一个主内存，当多个处理机运算任务涉及到主内存中同一块区域时，就会出现各自的缓存数据不一致的问题。

为了解决缓存一致性问题，**需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作**。

![缓存一致性.png](https://i.loli.net/2020/04/24/hSyQrA4YaKvGen3.png)



## JMM

### 概念和理解

并发编程, 需要处理两个问题:

1. 线程间的通信
   1. 线程之间以何种机制来交换信息
2. 线程间的同步
   1. 线程之间以何种方式来控制线程之间执行的顺序, 以完成任务

有两种并发模型可以解决这两个问题, 区别如下: 

1. 线程间的通信
   1. 共享内存
      1. 通过写读内存中的公共状态进行隐式通信
   2. 消息传递
      1. 无公共状态, 通过发送消息进行显示通信
2. 线程间的同步
   1. 在共享内存并发模型中, 同步是显示的, 由我们显示指定(synchronized,  lock等)
   2. 在消息传递并发模型中, 消息的发送必须在消息的接受之前, 所以是隐式的

Java并发采用的是共享内存模式,  所以通信模式总是隐式的进行, 整个通信过程对于我们而言是完全透明的,  而JMM

就是用于控制Java线程之间的通信的, 所以对其有所了解,  对一些并发的奇奇怪怪的问题, 应该能迎刃而解.

JMM决定`一个共享变量的写入何时对另一个线程可见`. 从另一个方面可以理解为: JMM定义了线程和主内存之间的抽象关系: 线程之间的共享变量存储在`主内存`中, 每个线程都有自己的`本地内存`，**本地内存中保留了该线程使用到的变量的主内存的副本**，同时`本地内存`只是一种叫法，方便理解，和高速缓存并不一样，其实际上是不存在的，它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。

![JMM.png](https://i.loli.net/2020/05/31/dxUuqcFn8mMzbEy.png)

那么JMM是如何管理线程之间的通信的呢，共分为两个步骤

1. ThreadA将本地内存更新的共享变量，刷新到主内存中
2. ThreadB从主内存中读取ThreadA更新之后的共享变量

**举例:**

假设有一个共享变量`x`, 初始值为`0`,  然后线程A, B 本地内存中也均存有该共享变量的副本, 然后A执行时, 对`x`的值进行了修改(改为了2), 临时存放在自己的本地内存中,  当线程A和线程B之间需要通信的时候, 线程A会将本地内存的`x`的值刷新到主内存中, 此时  主内存的`x`的值为2, 之后线程B去主存中获取`x`的最新值, 之后刷新到自己的本地内存,  然后对`x`进行操作

> 注意，根据JMM的规定，**线程对共享变量的所有操作都必须在自己的本地内存中进行，不能直接从主内存中读取**。

从整体上来看, 线程之间的通信必须经过主内存, JMM通过`控制每个线程的本地内存和主内存之间的交互`,  为我们提供内存的可见性保证(可见性针对的是共享变量).

>  共享变量是啥:
>
> JVM运行时数据区划分为五大类, 对于每一个线程来说，栈都是私有的，而堆是共有的。也就是说在栈中的变量（局部变量、方法定义参数、异常处理器参数）不会在线程之间共享，也就不会有内存可见性的问题，也不受内存模型的影响。而在堆中的变量是共享的，也即是所谓的共享变量。

这些我也是从`Java并发编程的艺术`上看来的, 总结性的概括JMM的话, 可以根据以上的概述理一理:

> JMM用于控制Java多线程之间的通信,  其决定了一个共享变量的写入何时对另一个线程可见, 由此抽象出了本地内存的概念, 同时JMM通过本地内存和主内存的交互保证了内存的可见性

### 重排序

计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排。

#### **为什么指令重排序可以提高性能？**

> 简单地说，每一个指令都会包含多个步骤，每个步骤可能使用不同的硬件。因此，**流水线技术**产生了，它的原理是指令1还没有执行完，就可以开始执行指令2，而不用等到指令1执行结束之后再执行指令2，这样就大大提高了效率。
>
> 但是，流水线技术最害怕**中断**，恢复中断的代价是比较大的，所以我们要想尽办法不让流水线中断。指令重排就是减少中断的一种技术。
>
> 我们分析一下下面这个代码的执行情况：
>
> ```java
> a = b + c;
> d = e - f ;
> ```
>
> 先加载b、c（**注意，即有可能先加载b，也有可能先加载c**），但是在执行add(b,c)的时候，需要等待b、c装载结束才能继续执行，也就是增加了停顿，那么后面的指令也会依次有停顿,这降低了计算机的执行效率。
>
> 为了减少这个停顿，我们可以先加载e和f,然后再去加载add(b,c),这样做对程序（串行）是没有影响的,但却减少了停顿。既然add(b,c)需要停顿，那还不如去做一些有意义的事情。
>
> 综上所述，**指令重排对于提高CPU处理性能十分必要。虽然由此带来了乱序的问题，但是这点牺牲是值得的。**

![指令重排序](https://i.loli.net/2020/05/31/nqjMLEPSVfF5OGI.png)

JMM属于语言级的内存模型,它确保在不同的编译器和不同的处理器平台之上,通过禁止特定类型的编译器重排序和处理器重排序,为程序员提供一致的内存可见性保证。

重排序有两类，JMM对这两类重排序有不同的策略：

- 会改变程序执行结果的重排序，比如 A -> C，JMM要求编译器和处理器都禁止这种重排序。
- 不会改变程序执行结果的重排序，比如 A -> B，JMM对编译器和处理器不做要求，允许这种重排序。



### 顺序一致性

当程序未正确同步的时候，就可能存在数据竞争。

> 数据竞争：在一个线程中写一个变量，在另一个线程读同一个变量，并且写和读没有通过同步来排序。

如果程序中包含了数据竞争，那么运行的结果往往充满了**不确定性**，比如读发生在了写之前，可能就会读到错误的值；如果一个线程程序能够正确同步，那么就不存在数据竞争。

Java内存模型（JMM）对于正确同步多线程程序的内存一致性做了以下保证：

> **如果程序是正确同步的，程序的执行将具有顺序一致性**。 即程序的执行结果和该程序在顺序一致性模型中执行的结果相同。

### happens-before

happens-before是JMM最核心的概念。理解happens-before是理解JMM的关键。

一方面，程序员需要JMM提供一个强的内存模型来编写代码；另一方面，编译器和处理器希望JMM对它们的束缚越少越好，这样它们就可以最可能多的做优化来提高性能，希望的是一个弱的内存模型。JMM考虑了这两种需求，并且找到了平衡点

1. 对于编译器和处理器而言:
   1. 只要不改变程序的运行结果(**单线程程序和正确同步了的多线程程序**), 编译器和处理器怎么优化都行
2. 对于程序员而言, 提供了happens-befors规则:
   1. 简单易懂, 并提供了足够强的内存可见性保证

#### happens-before关系定义如下:

1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。
2. **两个操作之间存在happens-before关系，编译器和处理器必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么JMM也允许这样的重排序。**

**happens-before关系保证正确同步的多线程程序的执行结果不被重排序改变。**

总之，**如果操作A happens-before操作B，那么操作A在内存上所做的操作对操作B都是可见的，不管它们在不在一个线程。**

#### happens-before的一些法则

1. 程序次序法则：如果在程序中，所有动作 A 出现在动作 B 之前，则线程中的每动作 A 都 happens-before 于该线程中的每一个动作 B。
2. 监视器锁法则：对一个监视器的解锁 happens-before 于每个后续对同一监视器的加锁。
3. Volatile 变量法则：对 Volatile 域的写入操作 happens-before 于每个后续对同一 Volatile 的读操作。
4. 传递性：如果 A happens-before 于 B，且 B happens-before C，则 A happens-before C。



#### 举例

```java
int a = 1; // A操作
int b = 2; // B操作
int sum = a + b;// C 操作
System.out.println(sum);
```

根据happens-before规则, 若是只有一个线程, 那么不难推出

```tex
1> A happens-before B 
2> B happens-before C 
3> A happens-before C
```

也正如上述的关系2中所说, 在执行指令的时候, JVM可能先执行B在执行A后执行C,  但是并不影响最后的结果

## References

* JSR-133: JavaTM Memory Model and Thread Specification
* Java并发编程的艺术
* 深入浅出Java多线程